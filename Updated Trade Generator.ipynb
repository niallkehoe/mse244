{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.tsa.api import VAR\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import pickle\n",
    "import databento as db\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FOLDER = \"./data/stock/\"\n",
    "# # NOTE: Decrease num_months_traing low if running too slow\n",
    "# num_months_train = 11\n",
    "# train_files = sorted_files[:num_months_train]   #Â 11 months as training set\n",
    "# test_files = sorted_files[-1:]    # choose last month as the test set\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# for file_name in tqdm(train_files, desc=\"Loading Training files\"):\n",
    "#     path = DATA_FOLDER + file_name\n",
    "#     stored_data = db.DBNStore.from_file(path)\n",
    "#     month_options = stored_data.to_df()\n",
    "#     df = pd.concat([df, month_options])\n",
    "\n",
    "# train_prices = df.pivot_table(index='ts_event', columns='symbol', values='close', aggfunc='first')\n",
    "# train_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        169.220\n",
      "1        169.220\n",
      "2        169.220\n",
      "3        169.220\n",
      "4        169.220\n",
      "          ...   \n",
      "98428    174.020\n",
      "98429    174.135\n",
      "98430    174.130\n",
      "98431    174.150\n",
      "98432    174.115\n",
      "Name: AAPL, Length: 98433, dtype: float64 0           NaN\n",
      "1           NaN\n",
      "2           NaN\n",
      "3           NaN\n",
      "4        307.31\n",
      "          ...  \n",
      "98428    397.48\n",
      "98429    397.44\n",
      "98430    397.37\n",
      "98431    397.37\n",
      "98432    397.18\n",
      "Name: MSFT, Length: 98433, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test_prices= pd.read_csv('/Users/kavitakar/Downloads/mse244-main/data/stock/1m_fullyear_equities.csv')\n",
    "\n",
    "\n",
    "print(test_prices[\"AAPL\"], test_prices[\"MSFT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.DataFrame()\n",
    "\n",
    "# for file_name in tqdm(test_files, desc=\"Loading Testing files\"):\n",
    "#     path = DATA_FOLDER + file_name\n",
    "#     stored_data = db.DBNStore.from_file(path)\n",
    "#     month_options = stored_data.to_df()\n",
    "#     df_test = pd.concat([df_test, month_options])\n",
    "\n",
    "# test_prices = df_test.pivot_table(index='ts_event', columns='symbol', values='close', aggfunc='first')\n",
    "# test_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # For displaying progress bars\n",
    "import logging  # For logging information\n",
    "from statsmodels.tsa.api import VAR  # Vector Autoregression model\n",
    "from statsmodels.tsa.stattools import coint  # Cointegration test\n",
    "from scipy.stats import norm  # For statistical functions\n",
    "\n",
    "class StraddleSelector:\n",
    "    def __init__(self, equities, lag_period, window_size=30):\n",
    "        \"\"\"\n",
    "        Initialize the StraddleSelector class with the list of equities, lag period, and window size for rolling calculations.\n",
    "\n",
    "        Parameters:\n",
    "        equities (list): List of equity tickers to analyze.\n",
    "        lag_period (int): The window size for rolling calculations.\n",
    "        window_size (int): The window size for rolling correlation (default is 30 minutes).\n",
    "        \"\"\"\n",
    "        self.equities = equities\n",
    "        self.lag_period = lag_period\n",
    "        self.window_size = window_size\n",
    "        self.var_models = {}  # Dictionary to store VAR models for each pair of equities\n",
    "        self.results = []\n",
    "        self.p_values_df = pd.DataFrame(columns=['Ticker1', 'Ticker2', 'P_Value', 'Correlation_Significant', 'Params', \"Best_Lag\"])\n",
    "        self.initial_calculation_done = False  # Flag to indicate if initial calculations are done\n",
    "        self.trade_signals = []\n",
    "        self.all_trades_df = pd.DataFrame()\n",
    "\n",
    "    def fetch_historical_data(self, ticker):\n",
    "        \"\"\"\n",
    "        Fetch historical data for a given ticker.\n",
    "\n",
    "        Parameters:\n",
    "        ticker (str): The equity ticker.\n",
    "\n",
    "        Returns:\n",
    "        pandas.Series: Historical adjusted close prices for the ticker.\n",
    "        \"\"\"\n",
    "        return test_prices[ticker]\n",
    "\n",
    "    def calculate_returns(self, historical_data):\n",
    "        \"\"\"\n",
    "        Calculate logarithmic returns from historical price data.\n",
    "\n",
    "        Parameters:\n",
    "        historical_data (pandas.Series): Historical adjusted close prices.\n",
    "\n",
    "        Returns:\n",
    "        pandas.Series: Logarithmic returns.\n",
    "        \"\"\"\n",
    "        return np.log(historical_data / historical_data.shift(1)).dropna()\n",
    "\n",
    "    def calculate_rolling_correlation(self, returns1, returns2):\n",
    "        \"\"\"\n",
    "        Calculate rolling correlation between two sets of returns.\n",
    "\n",
    "        Parameters:\n",
    "        returns1 (pandas.Series): Returns of the first equity.\n",
    "        returns2 (pandas.Series): Returns of the second equity.\n",
    "\n",
    "        Returns:\n",
    "        pandas.Series: Rolling correlation.\n",
    "        \"\"\"\n",
    "        return returns1.rolling(window=self.window_size).corr(returns2)\n",
    "\n",
    "    def fit_var_model(self, returns1, returns2, ticker1, ticker2):\n",
    "        \"\"\"\n",
    "        Fit a Vector Autoregression (VAR) model to the returns of two equities.\n",
    "\n",
    "        Parameters:\n",
    "        returns1 (pandas.Series): Returns of the first equity.\n",
    "        returns2 (pandas.Series): Returns of the second equity.\n",
    "        ticker1 (str): Ticker of the first equity.\n",
    "        ticker2 (str): Ticker of the second equity.\n",
    "\n",
    "        Returns:\n",
    "        VARResults: Fitted VAR model.\n",
    "        \"\"\"\n",
    "        model_data = pd.concat([returns1, returns2], axis=1).dropna()\n",
    "        model_data.columns = [ticker1, ticker2]\n",
    "        var_model = VAR(model_data)\n",
    "        return var_model.fit(maxlags=15, ic='aic')\n",
    "\n",
    "    def initial_calculations(self):\n",
    "        \"\"\"\n",
    "        Perform initial calculations including fetching data, calculating returns, and fitting VAR models.\n",
    "        \"\"\"\n",
    "        for i, ticker1 in enumerate(tqdm(self.equities)):\n",
    "            for ticker2 in self.equities[i + 1:]:\n",
    "                logging.info(f\"Initial analysis for pair: {ticker1}, {ticker2}\")\n",
    "\n",
    "                # Fetch historical data for the pair of equities\n",
    "                hist1 = self.fetch_historical_data(ticker1)\n",
    "                hist2 = self.fetch_historical_data(ticker2)\n",
    "\n",
    "                # Skip pairs with no data\n",
    "                if hist1.empty or hist2.empty:\n",
    "                    logging.warning(f\"No data for one or both tickers: {ticker1}, {ticker2}\")\n",
    "                    continue\n",
    "\n",
    "                merged_hist = pd.concat([hist1, hist2], axis=1).dropna()\n",
    "                if merged_hist.empty:\n",
    "                    logging.warning(f\"No data for pair: {ticker1}, {ticker2}\")\n",
    "                    continue\n",
    "\n",
    "                # Calculate returns for the pair\n",
    "                returns1 = self.calculate_returns(hist1)\n",
    "                returns2 = self.calculate_returns(hist2)\n",
    "\n",
    "                # Calculate rolling correlation and test its significance\n",
    "                rolling_corr = self.calculate_rolling_correlation(returns1, returns2)\n",
    "                significant = test_significance(rolling_corr.dropna())\n",
    "\n",
    "                if not significant:\n",
    "                    continue\n",
    "\n",
    "                # Fit VAR model and store results\n",
    "                var_result = self.fit_var_model(returns1, returns2, ticker1, ticker2)\n",
    "                self.store_p_values_and_models(ticker1, ticker2, var_result)\n",
    "                print(f\"Stored p values and models for {ticker1}, {ticker2}\")\n",
    "\n",
    "        self.initial_calculation_done = True\n",
    "\n",
    "    def store_p_values_and_models(self, ticker1, ticker2, var_result):\n",
    "        \"\"\"\n",
    "        Store p-values and VAR model parameters for a pair of equities.\n",
    "\n",
    "        Parameters:\n",
    "        ticker1 (str): Ticker of the first equity.\n",
    "        ticker2 (str): Ticker of the second equity.\n",
    "        var_result (VARResults): Fitted VAR model.\n",
    "        \"\"\"\n",
    "        p_value = coint(var_result.endog[:, 0], var_result.endog[:, 1])[1]\n",
    "        correlation_significant = p_value < 0.05\n",
    "        best_lag = var_result.k_ar\n",
    "        self.var_models[(ticker1, ticker2)] = var_result\n",
    "        new_row = pd.DataFrame({\n",
    "            'Ticker1': [ticker1],\n",
    "            'Ticker2': [ticker2],\n",
    "            'P_Value': [p_value],\n",
    "            'Correlation_Significant': [correlation_significant],\n",
    "            'Params': [var_result.params],\n",
    "            'Best_Lag': [best_lag]\n",
    "        })\n",
    "        self.p_values_df = pd.concat([self.p_values_df, new_row], ignore_index=True)\n",
    "\n",
    "    def forecast_volatility_change(self, var_model, test_data, ticker1, ticker2):\n",
    "        \"\"\"\n",
    "        Forecast changes in volatility using the VAR model.\n",
    "\n",
    "        Parameters:\n",
    "        var_model (VARResults): Fitted VAR model.\n",
    "        test_data (pandas.DataFrame): Test data for forecasting.\n",
    "        ticker1 (str): Ticker of the first equity.\n",
    "        ticker2 (str): Ticker of the second equity.\n",
    "\n",
    "        Returns:\n",
    "        pandas.DataFrame: Predicted volatility changes.\n",
    "        \"\"\"\n",
    "        lag_order = var_model.k_ar\n",
    "        if len(test_data) == 0 or lag_order == 0:\n",
    "            logging.warning(f\"Not enough data points to perform forecasting for {ticker1}, {ticker2}\")\n",
    "            return None\n",
    "\n",
    "        predicted_data = pd.DataFrame(columns=[ticker1, ticker2], index=test_data.index[lag_order:])\n",
    "        returns1 = self.calculate_returns(test_data[ticker1])\n",
    "        returns2 = self.calculate_returns(test_data[ticker2])\n",
    "        returns_concat = pd.concat([returns1, returns2], axis=1).dropna()\n",
    "\n",
    "        for i in range(0, len(returns_concat) - lag_order):\n",
    "            window = returns_concat.iloc[i:i + lag_order].values\n",
    "            forecast_results = var_model.forecast(y=window, steps=1)\n",
    "            predicted_data.loc[returns_concat.index[i + lag_order], ticker1] = forecast_results[0][0]\n",
    "            predicted_data.loc[returns_concat.index[i + lag_order], ticker2] = forecast_results[0][1]\n",
    "\n",
    "        final_predicted_data = pd.merge(returns_concat, predicted_data, left_index=True, right_index=True, suffixes=('_actual', '_predicted'))\n",
    "        window_size = 20\n",
    "\n",
    "        for ticker in [ticker1, ticker2]:\n",
    "            final_predicted_data[f'vol_{ticker}'] = final_predicted_data[f'{ticker}_predicted'].rolling(window=window_size).std()\n",
    "            final_predicted_data[f'shifted_vol_{ticker}'] = final_predicted_data[f'vol_{ticker}'].shift(1)\n",
    "            final_predicted_data[f'vol_change_{ticker}'] = final_predicted_data[f'vol_{ticker}'] - final_predicted_data[f'shifted_vol_{ticker}']\n",
    "            final_predicted_data[f'vol_std_{ticker}'] = final_predicted_data[f'vol_{ticker}'].rolling(window=window_size).std()\n",
    "            final_predicted_data.drop(columns=[f'shifted_vol_{ticker}'], inplace=True)\n",
    "\n",
    "        return final_predicted_data\n",
    "\n",
    "    def output_trades(self, final_predicted_data, ticker1, ticker2):\n",
    "        \"\"\"\n",
    "        Generate trade signals based on predicted data.\n",
    "\n",
    "        Parameters:\n",
    "        final_predicted_data (pandas.DataFrame): Predicted volatility changes.\n",
    "        ticker1 (str): Ticker of the first equity.\n",
    "        ticker2 (str): Ticker of the second equity.\n",
    "\n",
    "        Returns:\n",
    "        pandas.DataFrame: DataFrame containing trade signals.\n",
    "        \"\"\"\n",
    "        if final_predicted_data is None:\n",
    "            return None\n",
    "\n",
    "        for ticker in [ticker1, ticker2]:\n",
    "            percentile_25 = final_predicted_data[f'{ticker}_predicted'].quantile(0.25)\n",
    "            percentile_75 = final_predicted_data[f'{ticker}_predicted'].quantile(0.75)\n",
    "            final_predicted_data[f'{ticker}_trade'] = np.where(\n",
    "                final_predicted_data[f'{ticker}_predicted'] > percentile_75, 'C',\n",
    "                np.where(final_predicted_data[f'{ticker}_predicted'] < percentile_25, 'P', np.nan)\n",
    "            )\n",
    "\n",
    "        trades = final_predicted_data[[f'{ticker1}_trade', f'{ticker2}_trade']].dropna().reset_index()\n",
    "        trades.columns = ['date', 'trade_ticker1', 'trade_ticker2']\n",
    "        trades['ticker1'] = ticker1\n",
    "        trades['ticker2'] = ticker2\n",
    "        self.trade_signals.append(trades)\n",
    "\n",
    "        return trades\n",
    "\n",
    "    def update_decisions(self, test_prices):\n",
    "        \"\"\"\n",
    "        Update trading decisions based on new test prices.\n",
    "\n",
    "        Parameters:\n",
    "        test_prices (pandas.DataFrame): New test prices for equities.\n",
    "\n",
    "        Returns:\n",
    "        pandas.DataFrame: Updated DataFrame with all trades.\n",
    "        \"\"\"\n",
    "        if not self.initial_calculation_done:\n",
    "            logging.info(\"Initial calculations not done yet.\")\n",
    "            return None\n",
    "\n",
    "        for (ticker1, ticker2), var_result in self.var_models.items():\n",
    "            logging.info(f\"Updating decisions for pair: {ticker1}, {ticker2}\")\n",
    "            test_data = test_prices[[ticker1, ticker2]].dropna()\n",
    "            final_predicted_data = self.forecast_volatility_change(var_result, test_data, ticker1, ticker2)\n",
    "            trades_df = self.output_trades(final_predicted_data, ticker1, ticker2)\n",
    "            if trades_df is not None:\n",
    "                self.all_trades_df = pd.concat([self.all_trades_df, trades_df])\n",
    "\n",
    "        return self.all_trades_df\n",
    "\n",
    "    def run_iterations(self, num_iterations, test_prices):\n",
    "        \"\"\"\n",
    "        Run multiple iterations to update trading decisions.\n",
    "\n",
    "        Parameters:\n",
    "        num_iterations (int): Number of iterations to run.\n",
    "        test_prices (pandas.DataFrame): Test prices for equities.\n",
    "        \"\"\"\n",
    "        for i in range(num_iterations):\n",
    "            logging.info(f\"Running iteration {i + 1}/{num_iterations}\")\n",
    "            self.update_decisions(test_prices)\n",
    "            logging.info(f\"Iteration {i + 1} completed\")\n",
    "\n",
    "def rolling_correlation(data1, data2, window=30):\n",
    "    \"\"\"\n",
    "    Calculate rolling correlation between two data series.\n",
    "\n",
    "    Parameters:\n",
    "    data1 (pandas.Series): First data series.\n",
    "    data2 (pandas.Series): Second data series.\n",
    "    window (int): Rolling window size.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Rolling correlation.\n",
    "    \"\"\"\n",
    "    return data1.rolling(window).corr(data2)\n",
    "\n",
    "def test_significance(correlation_series, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test the significance of the rolling correlation series.\n",
    "\n",
    "    Parameters:\n",
    "    correlation_series (pandas.Series): Rolling correlation series.\n",
    "    alpha (float): Significance level.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if correlation is significant, False otherwise.\n",
    "    \"\"\"\n",
    "    mean_corr = correlation_series.mean()\n",
    "    std_corr = correlation_series.std()\n",
    "    t_stat = mean_corr / (std_corr / np.sqrt(len(correlation_series)))\n",
    "    p_value = 2 * (1 - norm.cdf(np.abs(t_stat)))  # Two-tailed test\n",
    "    return p_value < alpha\n",
    "\n",
    "def bayesian_inference(S, returns, window_size, n=10000):\n",
    "    \"\"\"\n",
    "    Perform Bayesian inference to predict future prices.\n",
    "\n",
    "    Parameters:\n",
    "    S (float): Current stock price.\n",
    "    returns (pandas.Series): Historical returns.\n",
    "    window_size (int): Rolling window size for correlation.\n",
    "    n (int): Number of samples.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Mean and standard deviation of predicted future prices.\n",
    "    \"\"\"\n",
    "    rolling_corr = returns.rolling(window=window_size).corr().dropna()\n",
    "    vol_change = rolling_corr.mean()\n",
    "    std_change = rolling_corr.std()\n",
    "    predicted_changes = np.random.normal(loc=vol_change, scale=std_change, size=n)\n",
    "    future_prices = S * (1 + predicted_changes)\n",
    "    return future_prices.mean(), future_prices.std()\n",
    "\n",
    "def binomial_tree_american(S, K, T, r, sigma, option_type='call', steps=100):\n",
    "    \"\"\"\n",
    "    Calculate the price of an American option using the binomial tree model.\n",
    "\n",
    "    Parameters:\n",
    "    S (float): Current stock price.\n",
    "    K (float): Strike price.\n",
    "    T (float): Time to maturity (in years).\n",
    "    r (float): Risk-free interest rate.\n",
    "    sigma (float): Volatility of the stock.\n",
    "    option_type (str): Type of the option ('call' or 'put').\n",
    "    steps (int): Number of steps in the binomial tree.\n",
    "\n",
    "    Returns:\n",
    "    float: Option price.\n",
    "    \"\"\"\n",
    "    dt = T / steps\n",
    "    u = np.exp(sigma * np.sqrt(dt))\n",
    "    d = 1 / u\n",
    "    p = (np.exp(r * dt) - d) / (u - d)\n",
    "    \n",
    "    option_values = np.zeros((steps + 1, steps + 1))\n",
    "    \n",
    "    for i in range(steps + 1):\n",
    "        if option_type == 'call':\n",
    "            option_values[i, steps] = max(0, S * (u ** (steps - i)) * (d ** i) - K)\n",
    "        elif option_type == 'put':\n",
    "            option_values[i, steps] = max(0, K - S * (u ** (steps - i)) * (d ** i))\n",
    "    \n",
    "    for j in range(steps - 1, -1, -1):\n",
    "        for i in range(j + 1):\n",
    "            option_value_if_held = np.exp(-r * dt) * (p * option_values[i, j + 1] + (1 - p) * option_values[i + 1, j + 1])\n",
    "            if option_type == 'call':\n",
    "                option_value_if_exercised = S * (u ** i) * (d ** (j - i)) - K\n",
    "            elif option_type == 'put':\n",
    "                option_value_if_exercised = K - S * (u ** i) * (d ** (j - i))\n",
    "            \n",
    "            option_values[i, j] = max(option_value_if_held.item(), option_value_if_exercised.item())\n",
    "\n",
    "    return option_values[0, 0]\n",
    "\n",
    "def straddle_profit(S, K, T, r, sigma, returns, window_size, steps=100):\n",
    "    \"\"\"\n",
    "    Calculate the profit of a straddle option strategy.\n",
    "\n",
    "    Parameters:\n",
    "    S (float): Current stock price.\n",
    "    K (float): Strike price of the options.\n",
    "    T (float): Time to maturity (in years).\n",
    "    r (float): Risk-free interest rate.\n",
    "    sigma (float): Volatility of the stock.\n",
    "    returns (pandas.Series): Historical returns.\n",
    "    window_size (int): Rolling window size for correlation.\n",
    "    steps (int): Number of steps in the binomial tree (default is 100).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing potential profits for upward, downward, and no price movement scenarios.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are valid\n",
    "    if S <= 0 or K <= 0 or T <= 0 or sigma <= 0 or steps <= 0:\n",
    "        raise ValueError(\"All input parameters must be positive.\")\n",
    "\n",
    "    # Incorporate Bayesian inference to adjust the initial stock price\n",
    "    S = bayesian_inference(S, returns, window_size, n=10000)[0]\n",
    "\n",
    "    # Calculate call and put option prices using the binomial tree model\n",
    "    call_price = binomial_tree_american(S, K, T, r, sigma, 'call', steps)\n",
    "    put_price = binomial_tree_american(S, K, T, r, sigma, 'put', steps)\n",
    "    total_cost = call_price + put_price\n",
    "\n",
    "    # Expected stock prices based on volatility\n",
    "    S_up = S * np.exp(sigma * np.sqrt(T))\n",
    "    S_down = S * np.exp(-sigma * np.sqrt(T))\n",
    "\n",
    "    # Calculate profits for different scenarios\n",
    "    profit_up = max(S_up - K, 0) + max(K - S_up, 0) - total_cost\n",
    "    profit_down = max(K - S_down, 0) + max(S_down - K, 0) - total_cost\n",
    "    profit_no_move = -total_cost\n",
    "\n",
    "    return {\n",
    "        'profit_up': profit_up,\n",
    "        'profit_down': profit_down,\n",
    "        'profit_no_move': profit_no_move,\n",
    "        'total_cost': total_cost\n",
    "    }\n",
    "\n",
    "def objective(K, S, T, r, sigma, returns, window_size, steps=100):\n",
    "    \"\"\"\n",
    "    Objective function to optimize the straddle profit.\n",
    "\n",
    "    Parameters:\n",
    "    K (float): Strike price.\n",
    "    S (float): Current stock price.\n",
    "    T (float): Time to maturity.\n",
    "    r (float): Risk-free interest rate.\n",
    "    sigma (float): Volatility.\n",
    "    returns (pandas.Series): Historical returns.\n",
    "    window_size (int): Rolling window size for correlation.\n",
    "    steps (int): Number of steps in the binomial tree.\n",
    "\n",
    "    Returns:\n",
    "    float: Negative of the sum of potential profits.\n",
    "    \"\"\"\n",
    "    profit = straddle_profit(S, K, T, r, sigma, returns, window_size, steps)\n",
    "    return - (profit['profit_up'] + profit['profit_down'] + profit['profit_no_move'])\n",
    "\n",
    "def sharpe_ratio(profits, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Calculate the Sharpe ratio for a series of profits.\n",
    "\n",
    "    Parameters:\n",
    "    profits (list or numpy.ndarray): Series of profits.\n",
    "    risk_free_rate (float): Risk-free interest rate.\n",
    "\n",
    "    Returns:\n",
    "    float: Sharpe ratio.\n",
    "    \"\"\"\n",
    "    expected_return = np.mean(profits)\n",
    "    std_dev = np.std(profits)\n",
    "    return (expected_return - risk_free_rate) / std_dev\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]INFO:root:Initial analysis for pair: AAPL, MSFT\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/var/folders/jn/h8_6ldvx1wz2fwvbpv9k_nmh0000gn/T/ipykernel_78022/1955668897.py:145: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.p_values_df = pd.concat([self.p_values_df, new_row], ignore_index=True)\n",
      "100%|ââââââââââ| 2/2 [00:00<00:00, 75.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored p values and models for AAPL, MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Running iteration 1/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 1 completed\n",
      "INFO:root:Running iteration 2/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 2 completed\n",
      "INFO:root:Running iteration 3/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 3 completed\n",
      "INFO:root:Running iteration 4/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 4 completed\n",
      "INFO:root:Running iteration 5/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 5 completed\n",
      "INFO:root:Running iteration 6/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 6 completed\n",
      "INFO:root:Running iteration 7/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 7 completed\n",
      "INFO:root:Running iteration 8/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         date trade_ticker1 trade_ticker2 ticker1 ticker2\n",
      "0   2023-06-09 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "1   2023-06-12 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "2   2023-06-13 00:00:00-04:00             C             P    AAPL    MSFT\n",
      "3   2023-06-14 00:00:00-04:00             P             P    AAPL    MSFT\n",
      "4   2023-06-15 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "..                        ...           ...           ...     ...     ...\n",
      "246 2024-06-03 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "247 2024-06-04 00:00:00-04:00             C             C    AAPL    MSFT\n",
      "248 2024-06-05 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "249 2024-06-06 00:00:00-04:00           nan             P    AAPL    MSFT\n",
      "250 2024-06-07 00:00:00-04:00             P           nan    AAPL    MSFT\n",
      "\n",
      "[251 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 8 completed\n",
      "INFO:root:Running iteration 9/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 9 completed\n",
      "INFO:root:Running iteration 10/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 10 completed\n",
      "INFO:root:Running iteration 11/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 11 completed\n",
      "INFO:root:Running iteration 12/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 12 completed\n",
      "INFO:root:Running iteration 13/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 13 completed\n",
      "INFO:root:Running iteration 14/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 14 completed\n",
      "INFO:root:Running iteration 15/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 15 completed\n",
      "INFO:root:Running iteration 16/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 16 completed\n",
      "INFO:root:Running iteration 17/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 17 completed\n",
      "INFO:root:Running iteration 18/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 18 completed\n",
      "INFO:root:Running iteration 19/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 19 completed\n",
      "INFO:root:Running iteration 20/20\n",
      "INFO:root:Updating decisions for pair: AAPL, MSFT\n",
      "INFO:root:Iteration 20 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         date trade_ticker1 trade_ticker2 ticker1 ticker2\n",
      "0   2023-06-09 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "1   2023-06-12 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "2   2023-06-13 00:00:00-04:00             C             P    AAPL    MSFT\n",
      "3   2023-06-14 00:00:00-04:00             P             P    AAPL    MSFT\n",
      "4   2023-06-15 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "..                        ...           ...           ...     ...     ...\n",
      "246 2024-06-03 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "247 2024-06-04 00:00:00-04:00             C             C    AAPL    MSFT\n",
      "248 2024-06-05 00:00:00-04:00           nan           nan    AAPL    MSFT\n",
      "249 2024-06-06 00:00:00-04:00           nan             P    AAPL    MSFT\n",
      "250 2024-06-07 00:00:00-04:00             P           nan    AAPL    MSFT\n",
      "\n",
      "[5271 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    equities = ['AAPL', 'MSFT']\n",
    "    lag_period = 30\n",
    "    straddle_selector = StraddleSelector(equities, lag_period)\n",
    "\n",
    "    straddle_selector.initial_calculations()\n",
    "\n",
    "    test_prices = pd.DataFrame()\n",
    "    for ticker in equities:\n",
    "        test_prices[ticker] = yf.Ticker(ticker).history(period=\"1y\")['Close']\n",
    "\n",
    "    all_trades_df = straddle_selector.update_decisions(test_prices)\n",
    "    print(all_trades_df)\n",
    "\n",
    "    num_iterations = 20\n",
    "    straddle_selector.run_iterations(num_iterations, test_prices)\n",
    "    print(straddle_selector.all_trades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "straddle_selector.all_trades_df.to_csv('straddle_trades.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
