{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto and Cross Correlation within the S&P 500 Returns\n",
    "\n",
    "## Objective: \n",
    "**Determine pairs, lags, correlation(direct & inverse), p-value, and magnitude of relationships between S&P 500 stock returns**\n",
    "## Approaches:\n",
    "\n",
    "\n",
    "## Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy \n",
    "# !pip install matplotlib\n",
    "# !pip install scipy\n",
    "# !pip install statsmodels\n",
    "# !pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf \n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import correlate\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color settings\n",
    "pink_colors = [\n",
    "    '#FFC0CB', '#FFB6C1', '#D8BFD8', '#DDA0DD', '#EE82EE', \n",
    "    '#DA70D6', '#FF69B4', '#FF1493', '#DB7093', '#C71585'\n",
    "]\n",
    "cmap = ListedColormap(pink_colors)\n",
    "\n",
    "soft_pink = '#FFF1FF'\n",
    "vivid_pink = '#FCC5FB'\n",
    "deep_pink = '#FF69B4'\n",
    "purple = '#FCF1FF'\n",
    "light_purple = '#FFF9FF'\n",
    "plum = '#5B095B'\n",
    "\n",
    "# yass\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'Avenir', \n",
    "    'axes.facecolor': light_purple,\n",
    "    'axes.edgecolor': vivid_pink,\n",
    "    'axes.labelcolor': vivid_pink,\n",
    "    'xtick.color': deep_pink,\n",
    "    'ytick.color': deep_pink,\n",
    "    'text.color': plum,\n",
    "    'legend.facecolor': soft_pink,\n",
    "    'legend.edgecolor': vivid_pink,\n",
    "    'figure.facecolor': light_purple  \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  YF Data & DB Data\n",
    "Import and join datasets of S&P 500 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500list = pd.read_csv('sp500list.txt', header=None)\n",
    "\n",
    "# Check list length\n",
    "len(sp500list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                       0%%                      ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  503 of 503 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "['GEV', 'SOLV']: Exception(\"%ticker%: Data doesn't exist for startDate = 1672549200, endDate = 1704085200\")\n",
      "['BF.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2023-01-01 -> 2024-01-01)')\n",
      "['BRK.B']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
     ]
    }
   ],
   "source": [
    "def fetch_stock_prices(symbols, start_date, end_date):\n",
    "    data = yf.download(symbols, start=start_date, end=end_date)\n",
    "    return data['Adj Close']\n",
    "\n",
    "symbols = list(sp500list.iloc[:, 0])\n",
    "start_date, end_date = '2023-01-01', '2024-01-01'\n",
    "yf_stock_prices = fetch_stock_prices(symbols, start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_stock_prices = pd.read_csv(\"1m_fullyear_equities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preprocess and Join Data\n",
    "\n",
    "**Data Cleaning:**\n",
    "Clean and preprocess the downloaded data, handling missing values and ensuring all data points are aligned by date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jn/h8_6ldvx1wz2fwvbpv9k_nmh0000gn/T/ipykernel_77255/4104894201.py:1: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  yf_stock_returns = yf_stock_prices.pct_change()\n"
     ]
    }
   ],
   "source": [
    "yf_stock_returns = yf_stock_prices.pct_change()\n",
    "yf_stock_returns = yf_stock_returns.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jn/h8_6ldvx1wz2fwvbpv9k_nmh0000gn/T/ipykernel_77255/3282509855.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  db_stock_prices.fillna(method='bfill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABNB</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>WTW</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_event</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-01 09:30:00+00:00</th>\n",
       "      <td>135.38</td>\n",
       "      <td>13.600</td>\n",
       "      <td>169.220</td>\n",
       "      <td>151.12</td>\n",
       "      <td>119.01</td>\n",
       "      <td>110.52</td>\n",
       "      <td>75.090</td>\n",
       "      <td>280.95</td>\n",
       "      <td>376.81</td>\n",
       "      <td>179.06</td>\n",
       "      <td>...</td>\n",
       "      <td>231.57</td>\n",
       "      <td>29.920</td>\n",
       "      <td>115.770</td>\n",
       "      <td>69.91</td>\n",
       "      <td>116.45</td>\n",
       "      <td>104.075</td>\n",
       "      <td>140.69</td>\n",
       "      <td>138.23</td>\n",
       "      <td>288.00</td>\n",
       "      <td>175.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 09:31:00+00:00</th>\n",
       "      <td>135.38</td>\n",
       "      <td>13.600</td>\n",
       "      <td>169.220</td>\n",
       "      <td>151.12</td>\n",
       "      <td>119.01</td>\n",
       "      <td>110.52</td>\n",
       "      <td>75.090</td>\n",
       "      <td>280.95</td>\n",
       "      <td>376.81</td>\n",
       "      <td>179.06</td>\n",
       "      <td>...</td>\n",
       "      <td>231.57</td>\n",
       "      <td>29.920</td>\n",
       "      <td>115.770</td>\n",
       "      <td>69.91</td>\n",
       "      <td>116.45</td>\n",
       "      <td>104.075</td>\n",
       "      <td>140.69</td>\n",
       "      <td>138.23</td>\n",
       "      <td>288.00</td>\n",
       "      <td>175.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 09:32:00+00:00</th>\n",
       "      <td>135.38</td>\n",
       "      <td>13.600</td>\n",
       "      <td>169.220</td>\n",
       "      <td>151.12</td>\n",
       "      <td>119.01</td>\n",
       "      <td>110.52</td>\n",
       "      <td>75.090</td>\n",
       "      <td>280.95</td>\n",
       "      <td>376.81</td>\n",
       "      <td>179.06</td>\n",
       "      <td>...</td>\n",
       "      <td>231.57</td>\n",
       "      <td>29.920</td>\n",
       "      <td>115.770</td>\n",
       "      <td>69.91</td>\n",
       "      <td>116.45</td>\n",
       "      <td>104.075</td>\n",
       "      <td>140.69</td>\n",
       "      <td>138.23</td>\n",
       "      <td>288.00</td>\n",
       "      <td>175.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 09:33:00+00:00</th>\n",
       "      <td>135.38</td>\n",
       "      <td>13.600</td>\n",
       "      <td>169.220</td>\n",
       "      <td>151.12</td>\n",
       "      <td>119.01</td>\n",
       "      <td>110.52</td>\n",
       "      <td>75.090</td>\n",
       "      <td>280.95</td>\n",
       "      <td>376.81</td>\n",
       "      <td>179.06</td>\n",
       "      <td>...</td>\n",
       "      <td>231.57</td>\n",
       "      <td>29.920</td>\n",
       "      <td>115.770</td>\n",
       "      <td>69.91</td>\n",
       "      <td>116.45</td>\n",
       "      <td>104.075</td>\n",
       "      <td>140.69</td>\n",
       "      <td>138.23</td>\n",
       "      <td>288.00</td>\n",
       "      <td>175.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 09:34:00+00:00</th>\n",
       "      <td>135.38</td>\n",
       "      <td>13.600</td>\n",
       "      <td>169.220</td>\n",
       "      <td>151.12</td>\n",
       "      <td>119.01</td>\n",
       "      <td>110.52</td>\n",
       "      <td>75.090</td>\n",
       "      <td>280.95</td>\n",
       "      <td>376.81</td>\n",
       "      <td>179.06</td>\n",
       "      <td>...</td>\n",
       "      <td>231.57</td>\n",
       "      <td>29.920</td>\n",
       "      <td>115.770</td>\n",
       "      <td>69.91</td>\n",
       "      <td>116.45</td>\n",
       "      <td>104.075</td>\n",
       "      <td>140.69</td>\n",
       "      <td>138.23</td>\n",
       "      <td>288.00</td>\n",
       "      <td>175.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 15:56:00+00:00</th>\n",
       "      <td>138.34</td>\n",
       "      <td>13.700</td>\n",
       "      <td>174.020</td>\n",
       "      <td>162.44</td>\n",
       "      <td>160.12</td>\n",
       "      <td>106.28</td>\n",
       "      <td>92.620</td>\n",
       "      <td>300.97</td>\n",
       "      <td>469.71</td>\n",
       "      <td>202.16</td>\n",
       "      <td>...</td>\n",
       "      <td>252.52</td>\n",
       "      <td>30.555</td>\n",
       "      <td>94.235</td>\n",
       "      <td>53.96</td>\n",
       "      <td>119.05</td>\n",
       "      <td>131.660</td>\n",
       "      <td>142.32</td>\n",
       "      <td>120.80</td>\n",
       "      <td>309.01</td>\n",
       "      <td>159.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 15:57:00+00:00</th>\n",
       "      <td>138.43</td>\n",
       "      <td>13.695</td>\n",
       "      <td>174.135</td>\n",
       "      <td>162.41</td>\n",
       "      <td>160.16</td>\n",
       "      <td>106.31</td>\n",
       "      <td>92.640</td>\n",
       "      <td>301.01</td>\n",
       "      <td>469.92</td>\n",
       "      <td>202.16</td>\n",
       "      <td>...</td>\n",
       "      <td>252.49</td>\n",
       "      <td>30.560</td>\n",
       "      <td>94.235</td>\n",
       "      <td>54.04</td>\n",
       "      <td>119.11</td>\n",
       "      <td>131.720</td>\n",
       "      <td>142.29</td>\n",
       "      <td>120.80</td>\n",
       "      <td>310.06</td>\n",
       "      <td>159.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 15:58:00+00:00</th>\n",
       "      <td>138.39</td>\n",
       "      <td>13.690</td>\n",
       "      <td>174.130</td>\n",
       "      <td>162.52</td>\n",
       "      <td>160.16</td>\n",
       "      <td>106.31</td>\n",
       "      <td>93.090</td>\n",
       "      <td>301.01</td>\n",
       "      <td>470.18</td>\n",
       "      <td>202.04</td>\n",
       "      <td>...</td>\n",
       "      <td>252.49</td>\n",
       "      <td>30.585</td>\n",
       "      <td>94.260</td>\n",
       "      <td>54.07</td>\n",
       "      <td>119.11</td>\n",
       "      <td>131.730</td>\n",
       "      <td>142.19</td>\n",
       "      <td>120.86</td>\n",
       "      <td>309.00</td>\n",
       "      <td>159.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 15:59:00+00:00</th>\n",
       "      <td>138.45</td>\n",
       "      <td>13.690</td>\n",
       "      <td>174.150</td>\n",
       "      <td>162.44</td>\n",
       "      <td>160.20</td>\n",
       "      <td>106.33</td>\n",
       "      <td>92.855</td>\n",
       "      <td>301.19</td>\n",
       "      <td>470.12</td>\n",
       "      <td>202.27</td>\n",
       "      <td>...</td>\n",
       "      <td>252.41</td>\n",
       "      <td>30.580</td>\n",
       "      <td>94.240</td>\n",
       "      <td>54.07</td>\n",
       "      <td>119.06</td>\n",
       "      <td>131.780</td>\n",
       "      <td>142.11</td>\n",
       "      <td>120.83</td>\n",
       "      <td>309.20</td>\n",
       "      <td>159.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 16:00:00+00:00</th>\n",
       "      <td>138.39</td>\n",
       "      <td>13.690</td>\n",
       "      <td>174.115</td>\n",
       "      <td>162.49</td>\n",
       "      <td>160.11</td>\n",
       "      <td>106.32</td>\n",
       "      <td>92.930</td>\n",
       "      <td>300.95</td>\n",
       "      <td>469.75</td>\n",
       "      <td>202.12</td>\n",
       "      <td>...</td>\n",
       "      <td>252.35</td>\n",
       "      <td>30.570</td>\n",
       "      <td>94.210</td>\n",
       "      <td>54.09</td>\n",
       "      <td>119.09</td>\n",
       "      <td>131.840</td>\n",
       "      <td>142.17</td>\n",
       "      <td>120.83</td>\n",
       "      <td>308.95</td>\n",
       "      <td>159.765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98433 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                A     AAL     AAPL    ABBV    ABNB     ABT  \\\n",
       "ts_event                                                                     \n",
       "2023-05-01 09:30:00+00:00  135.38  13.600  169.220  151.12  119.01  110.52   \n",
       "2023-05-01 09:31:00+00:00  135.38  13.600  169.220  151.12  119.01  110.52   \n",
       "2023-05-01 09:32:00+00:00  135.38  13.600  169.220  151.12  119.01  110.52   \n",
       "2023-05-01 09:33:00+00:00  135.38  13.600  169.220  151.12  119.01  110.52   \n",
       "2023-05-01 09:34:00+00:00  135.38  13.600  169.220  151.12  119.01  110.52   \n",
       "...                           ...     ...      ...     ...     ...     ...   \n",
       "2024-04-30 15:56:00+00:00  138.34  13.700  174.020  162.44  160.12  106.28   \n",
       "2024-04-30 15:57:00+00:00  138.43  13.695  174.135  162.41  160.16  106.31   \n",
       "2024-04-30 15:58:00+00:00  138.39  13.690  174.130  162.52  160.16  106.31   \n",
       "2024-04-30 15:59:00+00:00  138.45  13.690  174.150  162.44  160.20  106.33   \n",
       "2024-04-30 16:00:00+00:00  138.39  13.690  174.115  162.49  160.11  106.32   \n",
       "\n",
       "                             ACGL     ACN    ADBE     ADI  ...     WTW  \\\n",
       "ts_event                                                   ...           \n",
       "2023-05-01 09:30:00+00:00  75.090  280.95  376.81  179.06  ...  231.57   \n",
       "2023-05-01 09:31:00+00:00  75.090  280.95  376.81  179.06  ...  231.57   \n",
       "2023-05-01 09:32:00+00:00  75.090  280.95  376.81  179.06  ...  231.57   \n",
       "2023-05-01 09:33:00+00:00  75.090  280.95  376.81  179.06  ...  231.57   \n",
       "2023-05-01 09:34:00+00:00  75.090  280.95  376.81  179.06  ...  231.57   \n",
       "...                           ...     ...     ...     ...  ...     ...   \n",
       "2024-04-30 15:56:00+00:00  92.620  300.97  469.71  202.16  ...  252.52   \n",
       "2024-04-30 15:57:00+00:00  92.640  301.01  469.92  202.16  ...  252.49   \n",
       "2024-04-30 15:58:00+00:00  93.090  301.01  470.18  202.04  ...  252.49   \n",
       "2024-04-30 15:59:00+00:00  92.855  301.19  470.12  202.27  ...  252.41   \n",
       "2024-04-30 16:00:00+00:00  92.930  300.95  469.75  202.12  ...  252.35   \n",
       "\n",
       "                               WY     WYNN    XEL     XOM      XYL     YUM  \\\n",
       "ts_event                                                                     \n",
       "2023-05-01 09:30:00+00:00  29.920  115.770  69.91  116.45  104.075  140.69   \n",
       "2023-05-01 09:31:00+00:00  29.920  115.770  69.91  116.45  104.075  140.69   \n",
       "2023-05-01 09:32:00+00:00  29.920  115.770  69.91  116.45  104.075  140.69   \n",
       "2023-05-01 09:33:00+00:00  29.920  115.770  69.91  116.45  104.075  140.69   \n",
       "2023-05-01 09:34:00+00:00  29.920  115.770  69.91  116.45  104.075  140.69   \n",
       "...                           ...      ...    ...     ...      ...     ...   \n",
       "2024-04-30 15:56:00+00:00  30.555   94.235  53.96  119.05  131.660  142.32   \n",
       "2024-04-30 15:57:00+00:00  30.560   94.235  54.04  119.11  131.720  142.29   \n",
       "2024-04-30 15:58:00+00:00  30.585   94.260  54.07  119.11  131.730  142.19   \n",
       "2024-04-30 15:59:00+00:00  30.580   94.240  54.07  119.06  131.780  142.11   \n",
       "2024-04-30 16:00:00+00:00  30.570   94.210  54.09  119.09  131.840  142.17   \n",
       "\n",
       "                              ZBH    ZBRA      ZTS  \n",
       "ts_event                                            \n",
       "2023-05-01 09:30:00+00:00  138.23  288.00  175.770  \n",
       "2023-05-01 09:31:00+00:00  138.23  288.00  175.770  \n",
       "2023-05-01 09:32:00+00:00  138.23  288.00  175.770  \n",
       "2023-05-01 09:33:00+00:00  138.23  288.00  175.770  \n",
       "2023-05-01 09:34:00+00:00  138.23  288.00  175.770  \n",
       "...                           ...     ...      ...  \n",
       "2024-04-30 15:56:00+00:00  120.80  309.01  159.720  \n",
       "2024-04-30 15:57:00+00:00  120.80  310.06  159.800  \n",
       "2024-04-30 15:58:00+00:00  120.86  309.00  159.870  \n",
       "2024-04-30 15:59:00+00:00  120.83  309.20  159.860  \n",
       "2024-04-30 16:00:00+00:00  120.83  308.95  159.765  \n",
       "\n",
       "[98433 rows x 503 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_stock_prices = db_stock_prices.set_index('ts_event')\n",
    "db_stock_prices.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure that the data is in the numeric format\n",
    "for column in db_stock_prices.columns:\n",
    "    db_stock_prices[column] = pd.to_numeric(db_stock_prices[column], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jn/h8_6ldvx1wz2fwvbpv9k_nmh0000gn/T/ipykernel_77255/3712642574.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  db_stock_returns = db_stock_returns.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "db_stock_returns = db_stock_prices.pct_change()\n",
    "db_stock_returns = db_stock_returns.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Auto & Cross Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations_at_lags(data, max_lag=30):\n",
    "    results = {}\n",
    "    stocks = data.columns\n",
    "\n",
    "    # Calculate correlations for each pair of stocks at each lag\n",
    "    for i in stocks:\n",
    "        for j in stocks:\n",
    "            if i != j:\n",
    "                series1 = data[i]\n",
    "                series2 = data[j]\n",
    "                for lag in range(1, max_lag + 1):\n",
    "                    if lag not in results:\n",
    "                        results[lag] = []\n",
    "                    # Shift series2 by 'lag'\n",
    "                    shifted_series2 = series2.shift(lag)\n",
    "                    # Drop NA values caused by shifting\n",
    "                    valid_index = ~np.isnan(shifted_series2)\n",
    "                    # Calculate correlation and p-value\n",
    "                    if sum(valid_index) > 0:  # Ensure there are enough data points to calculate correlation\n",
    "                        corr, p_value = pearsonr(series1[valid_index], shifted_series2[valid_index])\n",
    "                        results[lag].append({\n",
    "                            'stock1': i,\n",
    "                            'stock2': j,\n",
    "                            'correlation': corr,\n",
    "                            'p_value': p_value,\n",
    "                            'lag': lag,\n",
    "                            'direct': 'direct' if corr > 0 else 'inverse'\n",
    "                        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_lag(correlations_at_lags):\n",
    "    best_lags = {}\n",
    "    for lags in correlations_at_lags.values():\n",
    "        for lag in lags:\n",
    "            stock1, stock2 = lag['stock1'], lag['stock2']\n",
    "            if (stock1, stock2) not in best_lags:\n",
    "                best_lags[(stock1, stock2)] = {\n",
    "                    'correlation': 0,\n",
    "                    'p_value': 1,\n",
    "                    'lag': 0,\n",
    "                    'direct': 'direct'\n",
    "                }\n",
    "            if abs(lag['correlation']) > abs(best_lags[(stock1, stock2)]['correlation']):\n",
    "                best_lags[(stock1, stock2)] = {\n",
    "                    'correlation': lag['correlation'],\n",
    "                    'p_value': lag['p_value'],\n",
    "                    'lag': lag['lag'],\n",
    "                    'direct': lag['direct']\n",
    "                }\n",
    "    return best_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_selected_lags_correlations(data, selected_lags):\n",
    "    num_stocks = len(data.columns)\n",
    "    stocks = data.columns.tolist()\n",
    "    results = []\n",
    "\n",
    "    for i in range(num_stocks):\n",
    "        series1 = data[stocks[i]].fillna(method='ffill').fillna(method='bfill').to_numpy()\n",
    "        for j in range(i + 1, num_stocks):  # avoid redundancy\n",
    "            \n",
    "            series2 = data[stocks[j]].fillna(method='ffill').fillna(method='bfill').to_numpy()\n",
    "\n",
    "            # Compute full cross-correlation\n",
    "            full_corr = signal.correlate(series2, series1, mode='full')\n",
    "            full_lags = signal.correlation_lags(len(series1), len(series2), mode='full')\n",
    "\n",
    "            # Extract correlations for selected lags\n",
    "            correlations = []\n",
    "            lags = []\n",
    "            for lag in selected_lags:\n",
    "                index = np.where(full_lags == lag)[0]\n",
    "                if index.size > 0:\n",
    "                    correlations.append(full_corr[index[0]])\n",
    "                    lags.append(full_lags[index[0]])\n",
    "\n",
    "            results.append({\n",
    "                'stock1': stocks[i],\n",
    "                'stock2': stocks[j],\n",
    "                'correlation': correlations,\n",
    "                'lags': lags\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "db_stock_returns = pd.read_csv(\"/content/db_stock_returns.csv\")\n",
    "for column in db_stock_returns.columns:\n",
    "    db_stock_returns[column] = pd.to_numeric(db_stock_returns[column], errors='coerce')\n",
    "\n",
    "selected_lags = [1, 5, 10, 20, 30, 60, 120, 180]\n",
    "correlation_results = calculate_selected_lags_correlations(db_stock_returns, selected_lags)\n",
    "\n",
    "\n",
    "flat_results = []\n",
    "for entry in correlation_results:\n",
    "    stock1 = entry['stock1']\n",
    "    stock2 = entry['stock2']\n",
    "    correlations = entry['correlation']\n",
    "    lags = entry['lags']\n",
    "\n",
    "    # Create a new dict for each correlation and lag\n",
    "    for corr, lag in zip(correlations, lags):\n",
    "        flat_results.append({\n",
    "            'stock1': stock1,\n",
    "            'stock2': stock2,\n",
    "            'correlation': corr,\n",
    "            'lag': lag\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def calculate_correlations(lag_df):\n",
    "    results = []\n",
    "    for i in range(len(lag_df)):\n",
    "        for j in range(i+1, len(lag_df)):  # Avoid duplicate pairs and self-correlation\n",
    "            specific_lag = lag_df['lag'].iloc[i]  # Get the specific lag for the current row\n",
    "            series1 = lag_df.iloc[:, i]\n",
    "            series2 = lag_df.iloc[:, j].shift(specific_lag)\n",
    "            valid_index = ~np.isnan(series2)\n",
    "            if sum(valid_index) > 0:  # Ensure there are enough data points to calculate correlation\n",
    "                corr, p_value = pearsonr(series1[valid_index], series2[valid_index])\n",
    "                results.append({\n",
    "                    'stock1': lag_df.columns[i],\n",
    "                    'stock2': lag_df.columns[j],\n",
    "                    'correlation': corr,\n",
    "                    'p_value': p_value,\n",
    "                    'lag': specific_lag,\n",
    "                    'direct': 'direct' if corr > 0 else 'inverse'\n",
    "                })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_at_lags = calculate_correlations_at_lags(stock_returns, max_lag=30)\n",
    "best_lags = pick_best_lag(correlations_at_lags)\n",
    "best_lags = pd.DataFrame(best_lags).T\n",
    "best_lags['r_squared'] = best_lags['correlation'] ** 2\n",
    "best_lags.sort_values('r_squared', ascending= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
